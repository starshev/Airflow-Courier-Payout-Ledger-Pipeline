# Courier Payout Ledger Pipeline using Airflow

### Task  
Build an end-to-end pipeline from scratch for daily incremental data load from a delivery service via API. Integrate the data into the DWH and construct a data mart functioning as a ledger for monthly courier payouts according to the provided schema.

### Skills  
ETL pipeline development using Airflow, API requests, incremental data loading, data integration into PostgreSQL-based DWH, data mart modeling and SQL scripting, writing functional Python modules, DAG creation with Python decorator and PostgresOperator, DAG execution testing, solution documentation.

## Пайплайн учёта выплат курьерам с использованием Airflow

### Задача  
Построить с нуля end-to-end пайплайн по ежедневной инкрементальной загрузке данных из службы доставки по API. Интегрировать данные в DWH на базе PostgreSQL и построить витрину данных с расчетом ежемесячных выплат курьерам согласно предоставленной схеме.

### Навыки  
Разработка сквозного ETL-пайплайна с использованием Airflow, API-запросы, инкрементальная загрузка данных, интеграция данных в DWH на базе PostgreSQL, моделирование витрины данных и написание SQL-скриптов, написание функциональных модулей на Python, создание DAG с использованием Python-декоратора и PostgresOperator, тестирование выполнения DAG, документирование решения.